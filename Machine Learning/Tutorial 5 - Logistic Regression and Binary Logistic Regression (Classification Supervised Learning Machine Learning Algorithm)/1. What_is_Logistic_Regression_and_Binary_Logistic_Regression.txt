What is Logistic Regression (LR)?
LR is a type of Supervised learning Classification Machine Learning (ML) algorithm that computes the 
relationship between a categorical dependent variable and at least one independent variables/features.

(Note: Compared to Supervised learning Regression ML algorithms, Supervised learning Classification
       ML algorithms refer to the dependent variable as 'categorical', because the dependent variable
       takes on discrete/distinct numerical values that are interpreted as a category, rather than 
       continuous numerical values)
       

Types of Logistic Regression (LR):
1. Binary Logistic Regression (will be covered in this tutorial)
2. Multinominal Logistic Regression (will be covered in 'Tutorial 5.1 - Multiclass Logistic
                                     Regression (Classification Supervised Learning Machine
                                     Learning Algorithm)')
3. Multiordinal Logistic Regression (will not be covered in these tutorials) (since it is slightly more
                                     complex)
                                     

///////////////////////////////////////////////////////////////////////////////////


What is the Binary Logistic Regression (BLR)?
BLR is a type of Supervised learning Classification Machine Learning (ML) algorithm that computes the 
relationship between a binary categorical dependent variable (aka only 2 possible categories, represented
by the values 0 and 1) and one or more than one independent variables/features.


///////////////////////////////////////////////////////////////////////////////////


How does the Binary Logistic Regression (BLR) Machine Learning (ML) algorithm work?
The BLR ML algorithm can be essentially represented by the mathematical equation:
        sigmoid(z) = 1 / (1 + ùëí^‚àíz)
 
where,
- 'ùëß' = m1*x1 + m2*x2 + m3*x3 + ... + m?*x? + b

  where,
  - 'x1', 'x2', 'x3' and 'x?' are the independent variables/features
  - 'm1', 'm2', 'm3' and 'm?' are the weights/gradients/coefficients of the independent variables/features 'x1', 'x2', 'x3' 
    and 'x?' respectively
  - 'b' is the bias/intercept (Note: For the BLR ML algorithm, 'b' does not represent the y-intercept! I will not explain why 
    and what exactly it is here, but to simplify things, just know that it is basically just a 'constant term')

  (Note: The '...' represents that there can any number of independent variables/features in the BLR ML algorithm)

- 'sigmoid()', the sigmoid/logit function, is 1 / (1 + ùëí^‚àíz), which is a function that maps any real number of z to a 
  value between 0 and 1 (it is able to do this because for any value of z, the denominator will always be at least equal 
  (when z = 0) or larger (when z < 0 or z < 0) than the nominator)
- 'sigmoid(z)' is the mapped value between 0 and 1 after any real number of z is passed through the 'sigmoid()', the 
  sigmoid/logit function
- 'ùëí' is the Euler's number ~ 2.71828



But the mathematical equation does not represent the full BLR ML algorithm! There is one extra step:
The rationale for using the sigmoid/logit function to mapping any real number of z to a value between 0 and 1 is so that
the real-number-of-z-now-a-value-between-0-and-1, 'sigmoid(z)', can be interpreted as a probability!

Using a probability threshold, which is usually 0.5 for BLR ML algorithm and since 'y' is the (binary categorical) 
dependent variable, 
-> if the real-number-of-z-now-a-value-between-0-and-1, 'sigmoid(z)', probability is larger than the probability threshold 
   of 0.5, then the (predicted) 'y' (binary categorical) dependent variable value for a set of values of the independent 
   variables/features for the BLR ML algorithm will be rounded up to 1, which can be interpreted as the (predicted) 'y' 
   (binary categorical) dependent variable value to be the category represented by the value of 1
-> if the real-number-of-z-now-a-value-between-0-and-1, 'sigmoid(z)', probability is smaller than the probability threshold 
   of 0.5, then the (predicted) 'y' (binary categorical) dependent variable value for a set of values of the independent 
   variables/features for the BLR ML algorithm will be rounded down to 0, which can be interpreted as the (predicted) 'y' 
   (binary categorical) dependent variable value to be the category represented by the value of 0


///////////////////////////////////////////////////////////////////////////////////


How does the Binary Logistic Regression (BLR) ML algorithm work in a context:
Lets say we have a dataset (a table of data) of 'bought insurance or not bought insurance' and just one variable affecting 
whether a person 'bought insurance or not bought insurance', the 'age' (dataset is referenced from 'bought_insurance_or_not_
bought_insurance_with_single_independent_variable_and_binary_categorical_dependent_variable.csv'). 

Learning from the 'Tutorial 4 - Machine Learning Encoding Techniques, One-hot Encoding Machine Learning Encoding Technique 
and Label Encoding Machine Learning Encoding Technique (Machine Learning Technique)' folder, where we learnt that you can 
represent categorical variables as values, by representing a person who 'bought insurance' as the value of 1, and a person 
who 'not bought insurance' as the value of 0, and also recalling from the 'Tutorial 2 - Linear Regression and Single Variable 
Linear Regression (Regression Supervised Learning Machine Learning Algorithm)' folder, the Single Variable Linear Regression
(SVLR) ML algorithm, we will try to use the SVLR ML algorithm on this dataset by plotting the data from this dataset in a 
scatter graph (as shown below), and drew a best fit straight line through the data (points) in the scatter graph with minimal 
error (Mean Square Error) between the best fit straight line and all the data (points) in the scatter graph. 

    bought insurance
or not bought insurance
        ^
    1.0 |                     +        +  +   +++ ++  +++ +/ +++
        |                                              __ /
        |                                          __ /
        |                                      __ /
        |                                  __ /
    0.5 |                              __ /
        |                          __ /
        |                      __ /
        |                  __ / 
        |             ++  /+++ +++++              + +
    0.0 |----------------------------------------------------------------------> age
        0                20             40             60             80

However, you will quickly notice that in the scatter graph there is high error between the best fit straight line through 
the data (points). No matter how you try to draw the best fit straight line through the data (points) you will only end up 
with a high error between the best fit straight line through the data (points). Hence, we can tell that for this 'bought 
insurance or not bought insurance' dataset, the SVLR ML algorithm will not work as it will give a high error and cause 
inaccurate predictions.  



So here is where BLR ML algorithm comes in! 
Lets say, instead of drawing a best fit straight line through the data (points) in the scatter graph, in order to draw a line
of better fit, with minimal error, we could draw a line through the data (points) in the scatter graph like this:

    bought insurance
or not bought insurance
        ^
    1.0 |                     +        +  +   +++ ++  +++ + +++
        |                                    _------------------
        |                                  _/
        |                                 / 
        |                                |
    0.5 |                                |
        |                              _/
        |                            _/
        |             _____________- 
        |             ++   +++ +++++              + +
    0.0 |----------------------------------------------------------------------> age
        0                20             40             60             80

(Note: Its hard to draw this 'S' shaped line in text. Refer to this codebasics Youtube video, titled 'Machine Learning 
 Tutorial Python - 8: Logistic Regression (Binary Classification)' 
 (link: https://www.youtube.com/watch?v=zM4VZR0px8E&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&index=13), at 
 timestamp 5:20 for a better visualisation of this 'S' shaped line)

So the important question is, how exactly do we come up with such a line through the data (points) in the scatter graph 
mathematically? And how is this line related to the BLR ML algorithm?

This line can be achieved using the Sigmoid/Logit function, and is essentially the mathematical equation that represents
the BLR ML algorithm.

The mathematical equation for the BLR ML algorithm in this context, aka the Machine Learning (ML) model for this 
context, is:
        sigmoid(z) = 1 / (1 + ùëí^‚àíz)
 
where,
- 'ùëß' = m * age + b

  where,
  - 'age' ('x') is the independent variable/feature
  - 'm' is the weight/gradient/coefficient of 'age' ('x')
  - 'b' is the bias/intercept, 'constant term'

- 'sigmoid()', the sigmoid/logit function, is 1 / (1 + ùëí^‚àíz), which is a function that maps any real number of z to a 
  value between 0 and 1 (it is able to do this because for any value of z, the denominator will always be at least equal 
  (when z = 0) or larger (when z < 0 or z < 0) than the nominator)
- 'sigmoid(z)' is the mapped value between 0 and 1 after any real number of z is passed through the 'sigmoid()', the 
  sigmoid/logit function
- 'ùëí' is the Euler's number ~ 2.71828


But the mathematical equation does not represent the full BLR ML algorithm! There is one extra step:
The rationale for using the sigmoid/logit function to mapping any real number of z to a value between 0 and 1 is so that
the real-number-of-z-now-a-value-between-0-and-1, 'sigmoid(z)', can be interpreted as a probability!

Using a probability threshold, which is usually 0.5 for BLR ML algorithm and since 'bought insurance or not bought insurance' 
('y') is the (binary categorical) dependent variable, 
-> if the real-number-of-z-now-a-value-between-0-and-1, 'sigmoid(z)', probability is larger than the probability threshold 
   of 0.5, then the (predicted) 'y' (binary categorical) dependent variable value for a set of values of the independent 
   variables/features for the BLR ML algorithm will be rounded up to 1, which can be interpreted as the (predicted) 'bought 
   insurance or not bought insurance' ('y') (binary categorical) dependent variable value to be the category represented by 
   the value of 1, which is the 'bought insurance' category
-> if the real-number-of-z-now-a-value-between-0-and-1, 'sigmoid(z)', probability is smaller than the probability threshold 
   of 0.5, then the (predicted) 'bought insurance or not bought insurance' ('y') (binary categorical) dependent variable value 
   for a set of values of the independent variables/features for the BLR ML algorithm will be rounded down to 0, which can be 
   interpreted as the (predicted) 'y' (binary categorical) dependent variable value to be the category represented by the 
   value of 0, which is the 'not bought insurance' category


///////////////////////////////////////////////////////////////////////////////////


So, how is the Binary Logistic Regression (BLR) a Machine Learning (ML) algorithm in this context?
The BLR is a ML algorithm because its algorithm allows it to make predictions. 

In this context, looking at the best fit sigmoid/logit line drawn in the scatter graph using the mathematical equation using 
the data from the dataset of the 'bought insurance or not bought insurance' and its only independent variable/feature, 
'age', we can predict, for example, whether someone have 'bought insurance' or 'not bought insurance' based on his age,
lets say 48 even though the dataset did not contain any data of whether someone of age 48 have 'bought insurance' or 'not 
bought insurance'.

Or you can think of it as substituting the value of the 'age' independent variable/feature into the mathematical equation 
for the BLR ML algorithm in this context, aka the Machine Learning (ML) model for this context, sigmoid(z) = 1 / (1 + ùëí^‚àíz)
where ùëß = m * age + b and 'bought insurance or not bought insurance' ('y') as the (binary categorical) dependent variable, 
to find the predicted 'bought insurance or not bought insurance' dependent variable.

    bought insurance
or not bought insurance
        ^
    1.0 |                     +        +  +   +++ ++  +++ + +++
        |                                    _------------------
  ~ 0.8 | - - - - - - - - - - - - - - - - -_/
        |                                 / |
        |                                |  |
    0.5 |                                |  |
        |                              _/   |
        |                            _/     |
        |             _____________-        |
        |             ++   +++ +++++        |     + +
    0.0 |----------------------------------------------------------------------> age
        0                20             40  48         60             80

(Note: Its hard to draw this 'S' shaped line in text. Refer to this codebasics Youtube video, titled 'Machine Learning 
 Tutorial Python - 8: Logistic Regression (Binary Classification)' 
 (link: https://www.youtube.com/watch?v=zM4VZR0px8E&list=PLeo1K3hjS3uvCeTYTeyfe0-rN5r8zn9rw&index=13), at 
 timestamp 5:20 for a better visualisation of this 'S' shaped line)

From the scatter graph, we can see that for a person of the 'age' independent variable/feature of 48, the value, interpreted
as a probability, of the 'bought insurance or not bought insurance' ('y') as the (binary categorical) dependent variable 
is approximately 0.8. Since, as per the BLR ML algorithm, is larger than the probability threshold of 0.5, hence this 
value, interpreted as a probability, will be rounded up to 1, which can be interpreted as the (predicted) 'bought insurance 
or not bought insurance' ('y') (binary categorical) dependent variable value to be the category represented by the value of 
1, which is the 'bought insurance' category, meaning that this BLR ML model in this context has predicted that person of the 
'age' independent variable/feature of 48 will have 'bought insurance'.


///////////////////////////////////////////////////////////////////////////////////


Additional note:
Since the mathematical equation that essentially represents the Binary Logistic Regression (BLR) ML algorithm, the 
Sigmoid/Logit function, looks like an 'S' shape, the data points further at the extreme ends of the 'S' shape probably 
have a more extreme probability (closer to 0 or 1) than data points in the middle?

Yes! You can tell by looking at the drawn 'S' shape Sigmoid/Logit line through the data (points) in the scatter graph, that
data points further at the extreme ends of the 'S' shape has a closer real-number-of-z-now-a-value-between-0-and-1, 
'sigmoid(z)', to the (predicted) 'y' (binary categorical) dependent variable values representing the 2 possible binary
categories, 0 and 1. 

Hence, these data points further at the extreme ends can be thought as being more 'confident/decisive' by the BLR ML model
to fall under the predicted respective 2 possible binary categories, which are represented by the (predicted) 'y' (binary 
categorical) dependent variable values, 0 and 1, since they will have a closer real-number-of-z-now-a-value-between-0-and-1, 
'sigmoid(z)', to the (predicted) 'y' (binary categorical) dependent variable values representing the 2 possible binary
categories, 0 and 1. 

While data points in the middle can be thought as being less 'confident/decisive' by the BLR ML model to fall under the 
predicted respective 2 possible binary categories, which are represented by the (predicted) 'y' (binary categorical) 
dependent variable values, 0 and 1, since they will have a further real-number-of-z-now-a-value-between-0-and-1, 
'sigmoid(z)', to the (predicted) 'y' (binary categorical) dependent variable values representing the 2 possible binary
categories, 0 and 1. 

Using the drawn 'S' shape Sigmoid/Logit line through the data (points) in the scatter graph from the context mentioned in 
the above section 'How does the Binary Logistic Regression (BLR) ML algorithm work in a context':
    bought insurance
or not bought insurance
        ^
    1.0 |                     +        +  +   +++ ++  +++ + +++
        |                                    _------------------
        |                                  _/
        |                                 / 
        |                                |
    0.5 |                                |
        |                              _/
        |                            _/
        |             _____________- 
        |             ++   +++ +++++              + +
    0.0 |----------------------------------------------------------------------> age
        0                20             40             60             80
                     |------------|----------|-----------------|
                          more        less          more
                       'confident  'confient     'confient
                       /decisive'  /decisive'    /decisive' 
                      data points  data points   data points