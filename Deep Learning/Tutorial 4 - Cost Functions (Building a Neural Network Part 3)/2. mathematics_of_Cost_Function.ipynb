{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab2786f",
   "metadata": {},
   "source": [
    "## Demonstrating how the mathematics of the Cost Functions look like\n",
    "However, do note that the codes here are all purely for demonstration purposes, for your understanding. It is very unlikely that you will need to implement these Cost Functions yourself when building Neural Networks, since DL libraries like PyTorch, TensorFlow and Keras, which you will most likely use when building Neural Networks, has already integrated all these in their ready-made API functions.\n",
    "\n",
    "We'll be going through 3 types of the most common Cost Functions used in Neural Networks:\n",
    "- Mean Absolute Error (MAE) Cost Function\n",
    "- Mean Square Error (MSE) Cost Function\n",
    "- Binary Logistic Loss/Binary Cross Entropy Cost Function\n",
    "\n",
    "Note:\n",
    "- yᵢ: represents actual data point value\n",
    "- ŷᵢ: represents prediction/data point value\n",
    "- n: represents the number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc22cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predicted = np.array([1,1,0,0,1])\n",
    "y_true = np.array([0.30,0.7,1,0,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc270e",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE) Cost Function\n",
    "MAE has the following mathematical forumula:  \n",
    "```\n",
    "MAE = (1/n) * Σ|yᵢ-ŷᵢ|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ded0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  2.5\n",
      "Mean Absolute Error (MAE) Cost Function:  0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Implementing Mean Absolute Error (MAE) Cost Function from scratch\n",
    "def mean_absolute_error_cost_function(y_true, y_predicted):\n",
    "    total_error = 0\n",
    "    for yt, yp in zip(y_true, y_predicted):\n",
    "        total_error += abs(yt - yp)\n",
    "    print(\"Total error: \", total_error)\n",
    "\n",
    "    mae = total_error / len(y_true)\n",
    "    print(\"Mean Absolute Error (MAE) Cost Function: \", mae)\n",
    "    return mae\n",
    "\n",
    "print(mean_absolute_error_cost_function(y_true, y_predicted))\n",
    "\n",
    "\n",
    "# Implementing Mean Absolute Error (MAE) Cost Function from scratch using NumPy\n",
    "print(np.mean(np.abs(y_predicted - y_true)))           # One line of code using NumPy does the same work as the above code, shows how powerful NumPy is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d699bf4",
   "metadata": {},
   "source": [
    "### Mean Square Error (MSE) Cost Function\n",
    "MSE has the following mathematical forumula:  \n",
    "```\n",
    "MSE = (1/n) * Σᵢ(yᵢ-ŷᵢ)²\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec91b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  1.83\n",
      "Mean Square Error (MSE) Cost Function:  0.366\n",
      "0.366\n",
      "0.366\n"
     ]
    }
   ],
   "source": [
    "# Implementing Mean Square Error (MSE) Cost Function from scratch\n",
    "def mean_square_error_cost_function(y_true, y_predicted):\n",
    "    total_error = 0\n",
    "    for yt, yp in zip(y_true, y_predicted):\n",
    "        total_error += pow(yt - yp, 2)\n",
    "    print(\"Total error: \", total_error)\n",
    "\n",
    "    mse = total_error / len(y_true)\n",
    "    print(\"Mean Square Error (MSE) Cost Function: \", mse)\n",
    "    return mse\n",
    "\n",
    "print(mean_square_error_cost_function(y_true, y_predicted))\n",
    "\n",
    "\n",
    "# Implementing Mean Square Error (MSE) Cost Function from scratch using NumPy\n",
    "print(np.mean(pow(y_predicted - y_true, 2)))           # One line of code using NumPy does the same work as the above code, shows how powerful NumPy is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd95c1",
   "metadata": {},
   "source": [
    "### Binary Logistic Loss/Binary Cross Entropy Cost Function\n",
    "Binary Logistic Loss/Binary Cross Entropy Cost Function has the following mathematical forumula:  \n",
    "```\n",
    "BinaryCrossEntropy = -(1/n) * Σ[yᵢ*log(ŷᵢ) + (1-yᵢ) * log(1-ŷᵢ)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cad119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.2696280766844\n"
     ]
    }
   ],
   "source": [
    "# Why so many extra steps to implement the Binary Logistic Loss/Binary Cross Entropy Cost Function?\n",
    "# This is because, looking at its formula:\n",
    "#       BinaryCrossEntropy = -(1/n) * Σ[yᵢ*log(ŷᵢ) + (1-yᵢ) * log(1-ŷᵢ)]\n",
    "\n",
    "# - looking at the term, log(ŷᵢ), if the predicted output, ŷᵢ is 0, it may cause an error in \n",
    "#   the code, since log(0) is undefined\n",
    "# - likewise, looking at the term, log(1-ŷᵢ), of the predicted output, ŷᵢ is 1, it may cause an \n",
    "#   error in the code, since log(1-1) = log(0) is undefined\n",
    "\n",
    "\n",
    "# To tackle this issue, we need to replace all the values of the predicted output, ŷᵢ to instead\n",
    "# of 0s and 1s,\n",
    "#           [1,1,0,0,1]\n",
    "# to where,\n",
    "# - the 0s are a value that is approximately 0 but not 0\n",
    "# - the 1s are a value that is approximately 1 but not 1\n",
    "\n",
    "# To do this, we define some approximately 0 value, epsilon. And then replace,\n",
    "# - the 0s to epsilon\n",
    "# - the 1s to 1 - epsilon\n",
    "\n",
    "\n",
    "# Implementing Mean Square Error (MSE) Cost Function from scratch\n",
    "def binary_logistic_loss_cost_function(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i, epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i, 1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true * np.log(y_predicted_new) + (1-y_true) * np.log(1-y_predicted_new))      # According to the mathematical \n",
    "                                                                                                    # formula of the Log Loss or Binary \n",
    "                                                                                                    # Cross Entropy Cost Function\n",
    "\n",
    "print(binary_logistic_loss_cost_function(y_true, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
